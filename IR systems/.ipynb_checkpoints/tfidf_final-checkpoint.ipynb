{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7ddcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from num2words import num2words\n",
    "from math import *\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ecc453",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=PorterStemmer()\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624d3502",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('postingLists',\"rb\")\n",
    "posting_lists=pickle.load(file)\n",
    "master_unique_words=set(posting_lists.keys())\n",
    "\n",
    "file=open('fileIndex','rb')\n",
    "file_index=pickle.load(file)\n",
    "\n",
    "file=open(\"fileWordList\",'rb')\n",
    "file_words=pickle.load(file)\n",
    "\n",
    "file=open(\"file_norms\",\"rb\")\n",
    "file_norms=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9985b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(querytext):\n",
    "    text=str(np.char.lower(querytext))\n",
    "    new_text = re.sub(r'[^\\w\\s]',' ',text)\n",
    "    token_list=word_tokenize(new_text)\n",
    "    word_list=token_list\n",
    "    for ind,word in enumerate(word_list):\n",
    "        if word.isdigit() and len(word)<4:\n",
    "            word_list[ind]=num2words(int(word))\n",
    "\n",
    "    word_list=' '.join(word_list)\n",
    "    word_list=re.sub(r'[^\\w\\s]',' ',word_list)\n",
    "    word_list=word_tokenize(word_list)\n",
    "    word_list=[word for word in word_list if word not in stop_words]\n",
    "    new_words=list(filter(lambda x:len(x)>1,word_list))\n",
    "    stem_words=[obj.stem(word) for word in new_words]\n",
    "    return stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c4a6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the queryblockchain technology\n",
      "['blockchain', 'technolog']\n"
     ]
    }
   ],
   "source": [
    "query_text=input(\"Enter the query\")\n",
    "final_stem_words = preprocess(query_text)\n",
    "total_docs_size=len(file_index)\n",
    "print(final_stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5778434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(word,filename):\n",
    "    idf=np.log((total_docs_size+1)/(len(posting_lists[word])+1))\n",
    "    freq=0\n",
    "    if filename in posting_lists[word].keys():   \n",
    "        freq=posting_lists[word][filename]\n",
    "        \n",
    "    tf_idf_val=idf*freq\n",
    "    \n",
    "    return tf_idf_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be0dcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vocab=list(set(final_stem_words))\n",
    "query_vector=np.zeros(len(query_vocab))\n",
    "\n",
    "for word in query_vocab:\n",
    "    term_freq=0\n",
    "    for it in final_stem_words:\n",
    "        if it == word:\n",
    "            term_freq+=1\n",
    "    num=0\n",
    "    if word in master_unique_words:\n",
    "        num = len(posting_lists[word])\n",
    "    idf=np.log2((total_docs_size+1)/(num+1))\n",
    "    pos=-1\n",
    "    for i in range(len(query_vocab)):\n",
    "        if query_vocab[i]==word:\n",
    "            pos=i\n",
    "            break\n",
    "    query_vector[pos]=term_freq*idf\n",
    "    \n",
    "query_vector=query_vector/np.linalg.norm(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53fd4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vector={}\n",
    "\n",
    "for filename in file_index.keys():\n",
    "    \n",
    "    document_vector[filename]=np.zeros(len(query_vocab))\n",
    "    for word in query_vocab:\n",
    "        if word in master_unique_words:\n",
    "            pos=-1\n",
    "            for i in range(len(query_vocab)):\n",
    "                if query_vocab[i]==word:\n",
    "                    pos=i\n",
    "                    break\n",
    "            document_vector[filename][pos]=get_tfidf(word,filename)\n",
    "    document_vector[filename]/=file_norms[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2203673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity={}\n",
    "\n",
    "for value in document_vector.keys():\n",
    "    cosine_similarity[value]=np.dot(document_vector[value],query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cad062a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C00008\n",
      "S00168\n",
      "S00129\n",
      "S00212\n",
      "S00554\n",
      "S00193\n",
      "S00593\n",
      "S00254\n",
      "S00469\n",
      "S00255\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity=sorted(cosine_similarity.items(),key=lambda x:x[1],reverse=True)\n",
    "tracker = 10\n",
    "for i in range(len(file_index)):\n",
    "    if tracker==0:\n",
    "        break\n",
    "    tracker-=1\n",
    "    value=cosine_similarity[i][0]\n",
    "    print(file_index[value][0].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106c0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6534f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
