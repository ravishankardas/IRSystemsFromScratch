{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from num2words import num2words\n",
    "import math\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=PorterStemmer()\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(querytext):\n",
    "    text=str(np.char.lower(querytext))\n",
    "    new_text = re.sub(r'[^\\w\\s]',' ',text)\n",
    "    token_list=word_tokenize(new_text)\n",
    "    word_list=token_list\n",
    "    for ind,word in enumerate(word_list):\n",
    "        if word.isdigit() and len(word)<4:\n",
    "            word_list[ind]=num2words(int(word))\n",
    "\n",
    "    word_list=' '.join(word_list)\n",
    "    word_list=re.sub(r'[^\\w\\s]',' ',word_list)\n",
    "    word_list=word_tokenize(word_list)\n",
    "    word_list=[word for word in word_list if word not in stop_words]\n",
    "    new_words=list(filter(lambda x:len(x)>1,word_list))\n",
    "    stem_words=[obj.stem(word) for word in new_words]\n",
    "    return stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('postingLists',\"rb\")\n",
    "posting_lists=pickle.load(file)\n",
    "\n",
    "file=open('fileIndex','rb')\n",
    "file_index=pickle.load(file)\n",
    "\n",
    "file=open(\"fileWordList\",'rb')\n",
    "file_words=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8930"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C00001.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the queryblockchain internet\n",
      "['blockchain', 'internet']\n"
     ]
    }
   ],
   "source": [
    "query_text=input(\"Enter the query\")\n",
    "final_stem_words = preprocess(query_text)\n",
    "total_docs_size=len(file_index)\n",
    "print(final_stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = 0\n",
    "for k,v in file_index.items():\n",
    "    total_words+=v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2787.198147075854"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_avg = total_words/total_docs_size\n",
    "# l_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1.2\n",
    "b = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for docid in file_words:\n",
    "    scores[docid]=0\n",
    "    for word in final_stem_words:\n",
    "        tf=0\n",
    "        doc_length = len(file_words[docid])\n",
    "        if word in posting_lists:\n",
    "            if docid in posting_lists[word]:\n",
    "                tf = posting_lists[word][docid]\n",
    "        df=0\n",
    "        if word in posting_lists:\n",
    "            df = len(posting_lists[word])\n",
    "        idf_num = len(file_index) + 0.5 - df\n",
    "        idf_den = 0.5 + df\n",
    "        idf = math.log(idf_num/idf_den)\n",
    "        val = ((b*doc_length)/l_avg)\n",
    "        bm25_den = tf + k*(1-b+val)\n",
    "        bm25_num = idf * tf*(k+1)\n",
    "        bm25_score = bm25_num/bm25_den\n",
    "        scores[docid] = bm25_score            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=10\n",
    "final_score = {}\n",
    "for i in scores:\n",
    "    final_score[file_index[i][0]]=scores[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = sorted(final_score.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C00017.txt\n",
      "C00345.txt\n",
      "S00311.txt\n",
      "C00363.txt\n",
      "S00472.txt\n",
      "L00062.txt\n",
      "D00915.txt\n",
      "C00939.txt\n",
      "D00901.txt\n",
      "S00857.txt\n"
     ]
    }
   ],
   "source": [
    "cnt=10\n",
    "for i in final_score:\n",
    "    if cnt==0:\n",
    "        break\n",
    "    cnt-=1\n",
    "    print(i[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e16b9bd33e7041c0842013505aab8d96e59e427e4e0c80436ba1b7c1f34f93b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
